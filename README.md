# Data Cleaning and Geographically Locating High Churn Risks

In this project, I cleaned a data set involving customer churn using Python.
In the following code, I checked for and corrected outliers, duplicates, invalid data, and missing values.
To do so, I used: Isolation forest algorithm, python methods, boolean masks, and K-Nearest Neighbor imputation respectively.

After I cleaned the data, I filtered for high churn risks and used matplotlib to create a bar graph of the ten highest
churn rates in each locational variables (state, county, city, etc.) The main findings are in the graphs below.



I concluded that the highest risks of churn are located in the midwest.
